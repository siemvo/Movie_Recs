{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09f664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vonks\\Documents\\GitHub\\Movie_Recs\\Downloads\n"
     ]
    }
   ],
   "source": [
    "# Data from https://grouplens.org/datasets/movielens/latest/\n",
    "# Put the downloaded csv files in the \"Downloads\" folder\n",
    "\n",
    "import os\n",
    "os.chdir(\"Downloads\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "366cf702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "data = ratings.merge(movies, on=\"movieId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84fecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  num_ratings\n",
      "0  189614        33332\n"
     ]
    }
   ],
   "source": [
    "# Removing users with more than 10,000 ratings as these are likely to be bots or outliers\n",
    "# See Data_Exploration.ipynb for more details about cleaning and outlier detection\n",
    "\n",
    "ratings_per_user = data.groupby('userId').size()\n",
    "outliers = ratings_per_user[ratings_per_user > 10000]\n",
    "filtered_data = data[~data['userId'].isin(outliers.index)]\n",
    "\n",
    "# Table of removed users\n",
    "removed_users_table = outliers.reset_index()\n",
    "removed_users_table.columns = ['userId', 'num_ratings']\n",
    "\n",
    "print(removed_users_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f340b0b4",
   "metadata": {},
   "source": [
    "## User Similarity Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47cb32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Parameters\n",
    "min_ratings_per_user = 20 # For selection of active users\n",
    "sample_size = 100\n",
    "K = 10 # Number of recommendations\n",
    "liked_threshold = 4\n",
    "top_n_input = 4 # Number of liked movies to use for similarity\n",
    "\n",
    "# Select active users\n",
    "active_users = filtered_data.groupby('userId').size()\n",
    "active_users = active_users[active_users >= min_ratings_per_user].index\n",
    "\n",
    "# Random sample of users because data is large\n",
    "np.random.seed(123)\n",
    "sampled_users = np.random.choice(active_users, size=sample_size, replace=False)\n",
    "\n",
    "# For each sampled user, split their movie ratings into train (80%) and test (20%)\n",
    "train_ratings = pd.DataFrame()\n",
    "test_ratings = pd.DataFrame()\n",
    "\n",
    "for uid in sampled_users:\n",
    "    user_data = filtered_data[filtered_data['userId'] == uid]\n",
    "    train, test = train_test_split(user_data, test_size=0.2, random_state=42)\n",
    "    train_ratings = pd.concat([train_ratings, train])\n",
    "    test_ratings = pd.concat([test_ratings, test])\n",
    "\n",
    "# -----------------------------\n",
    "# Build matrix from training data\n",
    "# -----------------------------\n",
    "user_ids = train_ratings['userId'].unique()\n",
    "movie_ids = train_ratings['movieId'].unique()\n",
    "user_to_idx = {uid:i for i, uid in enumerate(user_ids)} # Rows\n",
    "movie_to_idx = {mid:i for i, mid in enumerate(movie_ids)} # Columns\n",
    "\n",
    "# Empty matrix\n",
    "n_users = len(user_ids)\n",
    "n_movies = len(movie_ids)\n",
    "user_item_matrix = np.zeros((n_users, n_movies))\n",
    "\n",
    "# Fill matrix\n",
    "for row in train_ratings.itertuples():\n",
    "    u_idx = user_to_idx[row.userId]\n",
    "    m_idx = movie_to_idx[row.movieId]\n",
    "    user_item_matrix[u_idx, m_idx] = row.rating\n",
    "\n",
    "# -----------------------------\n",
    "# Generate recommendations using only top liked movies\n",
    "# -----------------------------\n",
    "user_metrics = []\n",
    "\n",
    "for uid in sampled_users:\n",
    "    u_idx = user_to_idx[uid]\n",
    "    user_vector = user_item_matrix[u_idx, :] # Ratings\n",
    "\n",
    "    # Select top-N liked movies only (positive ratings)\n",
    "    liked_indices = np.where(user_vector >= liked_threshold)[0]\n",
    "    if len(liked_indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    top_indices = np.argsort(user_vector[liked_indices])[-top_n_input:]\n",
    "    top_indices = liked_indices[top_indices]\n",
    "\n",
    "    # Find relevant users who rated at least one of these top-N movies\n",
    "    rel_users = np.any(user_item_matrix[:, top_indices] > 0, axis=1)\n",
    "    rel_users[u_idx] = False\n",
    "    relevant_users_matrix = user_item_matrix[rel_users, :]\n",
    "\n",
    "    if relevant_users_matrix.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # Cosine similarity on top-N liked movies\n",
    "    sims = cosine_similarity([user_vector[top_indices]], relevant_users_matrix[:, top_indices])[0]\n",
    "\n",
    "    # Compute weighted average for unseen movies based on similar users = prediction\n",
    "    unseen = np.where(user_vector == 0)[0]\n",
    "    weighted_scores = np.zeros(len(unseen))\n",
    "    for i, m_idx in enumerate(unseen):\n",
    "        weighted_scores[i] = np.sum(relevant_users_matrix[:, m_idx] * sims) / (np.sum(sims) + 1e-8)\n",
    "\n",
    "    # Top recommendations\n",
    "    top_recs_idx = np.argsort(weighted_scores)[::-1][:K] # Top K\n",
    "    recommended_movie_ids = [list(movie_to_idx.keys())[unseen[i]] for i in top_recs_idx]\n",
    "\n",
    "    # Test set \n",
    "    test_all = test_ratings[test_ratings['userId'] == uid]\n",
    "    test_liked = set(test_all[test_all['rating'] >= liked_threshold]['movieId'])\n",
    "    test_not_liked = set(test_all[test_all['rating'] < liked_threshold]['movieId'])\n",
    "\n",
    "    user_metrics.append({\n",
    "        'recommended': recommended_movie_ids,\n",
    "        'test_liked': test_liked,\n",
    "        'test_not_liked': test_not_liked\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30a6cf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations based on user similarity of liked movies:\n",
      "             Recommended  Not Recommended         Total\n",
      "Liked           1.130435        13.684783     14.815217\n",
      "Not Liked       0.543478        15.358696     15.902174\n",
      "Not Watched     8.326087     81781.956522  81790.282609\n",
      "\n",
      "Average metrics:\n",
      "Fraction of liked movies recommended in 10 recs: 0.094\n",
      "Precision in 10 recs: 0.113\n",
      "Recall in 10 recs: 0.094\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_movie_ids = set(filtered_data['movieId'].unique())\n",
    "K = 10  # top-K recommendations\n",
    "liked_threshold = 4.0\n",
    "\n",
    "counts_per_user = []\n",
    "hit_rates, precisions, recalls = [], [], []\n",
    "\n",
    "#filtered_user_metrics = [um for um in user_metrics if len(um['test_liked']) > 0]\n",
    "\n",
    "for um in user_metrics:\n",
    "    # Unpack the information per user (um)\n",
    "    recommended = set(um['recommended'])\n",
    "    test_liked = um['test_liked']\n",
    "    test_not_liked = um['test_not_liked']\n",
    "    test_movies = test_liked | test_not_liked\n",
    "\n",
    "    # Metrics for table\n",
    "    rec_watched_liked = len(recommended & test_liked)\n",
    "    rec_watched_not_liked = len(recommended & test_not_liked)\n",
    "    rec_not_watched = len(recommended - test_movies)\n",
    "\n",
    "    nonrec = all_movie_ids - recommended\n",
    "    nonrec_watched_liked = len(nonrec & test_liked)\n",
    "    nonrec_watched_not_liked = len(nonrec & test_not_liked)\n",
    "    nonrec_not_watched = len(nonrec - test_movies)\n",
    "\n",
    "    counts_per_user.append({\n",
    "        'Recommended_Watched+Liked': rec_watched_liked,\n",
    "        'Recommended_Watched+NotLiked': rec_watched_not_liked,\n",
    "        'Recommended_NotWatched': rec_not_watched,\n",
    "        'NotRecommended_Watched+Liked': nonrec_watched_liked,\n",
    "        'NotRecommended_Watched+NotLiked': nonrec_watched_not_liked,\n",
    "        'NotRecommended_NotWatched': nonrec_not_watched\n",
    "    })\n",
    "\n",
    "    # Hit Rate = 1 if at least one liked movie is recommended\n",
    "    #hit = 1 if len(recommended & test_liked) > 0 else 0\n",
    "    hit = len(recommended & test_liked) / len(test_liked) if len(test_liked) > 0 else 0\n",
    "\n",
    "    # Precision and Recall K\n",
    "    precision = len(recommended & test_liked) / len(recommended) if len(recommended) > 0 else 0\n",
    "    recall = len(recommended & test_liked) / len(test_liked) if len(test_liked) > 0 else 0\n",
    "    \n",
    "    hit_rates.append(hit)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "# Table with averages\n",
    "counts_df = pd.DataFrame(counts_per_user)\n",
    "average_counts = counts_df.mean()\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    'Recommended': [\n",
    "        average_counts['Recommended_Watched+Liked'],\n",
    "        average_counts['Recommended_Watched+NotLiked'],\n",
    "        average_counts['Recommended_NotWatched']\n",
    "    ],\n",
    "    'Not Recommended': [\n",
    "        average_counts['NotRecommended_Watched+Liked'],\n",
    "        average_counts['NotRecommended_Watched+NotLiked'],\n",
    "        average_counts['NotRecommended_NotWatched']\n",
    "    ]\n",
    "}, index=['Liked', 'Not Liked', 'Not Watched'])\n",
    "\n",
    "# Add totals column\n",
    "table['Total'] = table['Recommended'] + table['Not Recommended']\n",
    "\n",
    "print(\"Recommendations based on user similarity of liked movies:\")\n",
    "print(table)\n",
    "\n",
    "avg_hit_rate = np.mean(hit_rates)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "\n",
    "print(\"\\nAverage metrics:\")\n",
    "print(f\"Fraction of liked movies recommended in {K} recs: {avg_hit_rate:.3f}\")\n",
    "print(f\"Precision in {K} recs: {avg_precision:.3f}\")\n",
    "print(f\"Recall in {K} recs: {avg_recall:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066577d",
   "metadata": {},
   "source": [
    "## Recommending based on top 10 rated movies overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1548f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations based on top average movie ratings:\n",
      "                     Recommended  Not Recommended     Total\n",
      "Watched + Liked             0.59            14.95     15.54\n",
      "Watched + Not Liked         0.16            16.46     16.62\n",
      "Not Watched                 9.25         81779.59  81788.84\n",
      "\n",
      "Metrics:\n",
      "Fraction of liked movies recommended in 10 recs: 0.047\n",
      "Precision in 10 recs: 0.059\n",
      "Recall in 10 recs: 0.047\n",
      "\n",
      "Top 10 movies by average rating (min 20 ratings):\n",
      "1. Inception (2010) (average rating: 4.31, n_ratings: 21)\n",
      "2. Lord of the Rings: The Fellowship of the Ring, The (2001) (average rating: 4.31, n_ratings: 36)\n",
      "3. Star Wars: Episode V - The Empire Strikes Back (1980) (average rating: 4.29, n_ratings: 35)\n",
      "4. Shawshank Redemption, The (1994) (average rating: 4.27, n_ratings: 26)\n",
      "5. Usual Suspects, The (1995) (average rating: 4.27, n_ratings: 26)\n",
      "6. Reservoir Dogs (1992) (average rating: 4.26, n_ratings: 21)\n",
      "7. Schindler's List (1993) (average rating: 4.17, n_ratings: 20)\n",
      "8. Lord of the Rings: The Return of the King, The (2003) (average rating: 4.17, n_ratings: 33)\n",
      "9. Lord of the Rings: The Two Towers, The (2002) (average rating: 4.16, n_ratings: 34)\n",
      "10. Seven (a.k.a. Se7en) (1995) (average rating: 4.15, n_ratings: 24)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_movie_ids = set(filtered_data['movieId'].unique())\n",
    "K = 10\n",
    "liked_threshold = 4\n",
    "min_ratings_per_movie = 20\n",
    "\n",
    "# Top average movies\n",
    "# First filter movies with at least 20 ratings\n",
    "movie_counts = train_ratings.groupby('movieId').size()\n",
    "eligible_movies = movie_counts[movie_counts >= min_ratings_per_movie].index\n",
    "filtered_ratings = train_ratings[train_ratings['movieId'].isin(eligible_movies)]\n",
    "filtered_movies = filtered_ratings.groupby('movieId')['rating'].agg(['mean', 'count'])\n",
    "top_movies_by_avg = filtered_movies.sort_values('mean', ascending=False).head(K).index.tolist()\n",
    "\n",
    "# Calculate metrics for each user\n",
    "user_metrics_baseline = []\n",
    "\n",
    "for uid in sampled_users:\n",
    "    recommended = set(top_movies_by_avg)\n",
    "\n",
    "    test_all = test_ratings[test_ratings['userId'] == uid]\n",
    "    test_liked = set(test_all[test_all['rating'] >= liked_threshold]['movieId'])\n",
    "    test_not_liked = set(test_all[test_all['rating'] < liked_threshold]['movieId'])\n",
    "\n",
    "    user_metrics_baseline.append({\n",
    "        'recommended': recommended,\n",
    "        'test_liked': test_liked,\n",
    "        'test_not_liked': test_not_liked\n",
    "    })\n",
    "\n",
    "# Calculate counts and metrics\n",
    "counts_per_user = []\n",
    "hit_rates, precisions, recalls = [], [], []\n",
    "\n",
    "for um in user_metrics_baseline:\n",
    "    recommended = set(um['recommended'])\n",
    "    test_liked = um['test_liked']\n",
    "    test_not_liked = um['test_not_liked']\n",
    "    test_movies = test_liked | test_not_liked\n",
    "\n",
    "    rec_watched_liked = len(recommended & test_liked)\n",
    "    rec_watched_not_liked = len(recommended & test_not_liked)\n",
    "    rec_not_watched = len(recommended - test_movies)\n",
    "\n",
    "    nonrec = all_movie_ids - recommended\n",
    "    nonrec_watched_liked = len(nonrec & test_liked)\n",
    "    nonrec_watched_not_liked = len(nonrec & test_not_liked)\n",
    "    nonrec_not_watched = len(nonrec - test_movies)\n",
    "\n",
    "    counts_per_user.append({\n",
    "        'Recommended_Watched+Liked': rec_watched_liked,\n",
    "        'Recommended_Watched+NotLiked': rec_watched_not_liked,\n",
    "        'Recommended_NotWatched': rec_not_watched,\n",
    "        'NotRecommended_Watched+Liked': nonrec_watched_liked,\n",
    "        'NotRecommended_Watched+NotLiked': nonrec_watched_not_liked,\n",
    "        'NotRecommended_NotWatched': nonrec_not_watched\n",
    "    })\n",
    "\n",
    "    hit_rates.append(len(recommended & test_liked) / len(test_liked) if len(test_liked) > 0 else 0)\n",
    "    precisions.append(rec_watched_liked / K)\n",
    "    recalls.append(rec_watched_liked / len(test_liked) if len(test_liked) > 0 else 0)\n",
    "\n",
    "# Table\n",
    "counts_df = pd.DataFrame(counts_per_user)\n",
    "avg_counts = counts_df.mean()\n",
    "table = pd.DataFrame({\n",
    "    'Recommended': [\n",
    "        avg_counts['Recommended_Watched+Liked'],\n",
    "        avg_counts['Recommended_Watched+NotLiked'],\n",
    "        avg_counts['Recommended_NotWatched']\n",
    "    ],\n",
    "    'Not Recommended': [\n",
    "        avg_counts['NotRecommended_Watched+Liked'],\n",
    "        avg_counts['NotRecommended_Watched+NotLiked'],\n",
    "        avg_counts['NotRecommended_NotWatched']\n",
    "    ]\n",
    "}, index=['Watched + Liked', 'Watched + Not Liked', 'Not Watched'])\n",
    "\n",
    "table['Total'] = table['Recommended'] + table['Not Recommended']\n",
    "\n",
    "# Average metrics\n",
    "avg_hit_rate = np.mean(hit_rates)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "\n",
    "print(\"Recommendations based on top average movie ratings:\")\n",
    "print(table)\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"Fraction of liked movies recommended in {K} recs: {avg_hit_rate:.3f}\")\n",
    "print(f\"Precision in {K} recs: {avg_precision:.3f}\")\n",
    "print(f\"Recall in {K} recs: {avg_recall:.3f}\")\n",
    "\n",
    "# Top 10 movies (recommended)\n",
    "print(\"\\nTop 10 movies by average rating (min 20 ratings):\")\n",
    "for i, movieId in enumerate(top_movies_by_avg, start=1):\n",
    "    title = movies.loc[movies['movieId'] == movieId, 'title'].values[0]\n",
    "    avg_rating = filtered_movies.loc[movieId, 'mean']\n",
    "    n_ratings = filtered_movies.loc[movieId, 'count']\n",
    "    print(f\"{i}. {title} (average rating: {avg_rating:.2f}, n_ratings: {n_ratings})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
