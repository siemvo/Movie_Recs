{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b09f664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vonks\\Documents\\GitHub\\Movie_Recs\\Downloads\n"
     ]
    }
   ],
   "source": [
    "# Data from https://grouplens.org/datasets/movielens/latest/\n",
    "# Put the downloaded csv files in the \"Downloads\" folder\n",
    "\n",
    "import os\n",
    "os.chdir(\"Downloads\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366cf702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "data = ratings.merge(movies, on=\"movieId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded7942b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      userId  num_ratings\n",
      "0        149         1507\n",
      "1        198         1255\n",
      "2        305         1406\n",
      "3        461         1692\n",
      "4        487         2164\n",
      "...      ...          ...\n",
      "3646  330517         2304\n",
      "3647  330535         2791\n",
      "3648  330687         1535\n",
      "3649  330842         1288\n",
      "3650  330914         1404\n",
      "\n",
      "[3651 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Removing users with more than 1,000 ratings as these are likely to be bots or outliers\n",
    "# See Data_Exploration.ipynb for more details about cleaning and outlier detection\n",
    "\n",
    "ratings_per_user = data.groupby('userId').size()\n",
    "outliers = ratings_per_user[ratings_per_user > 1000]\n",
    "filtered_data = data[~data['userId'].isin(outliers.index)]\n",
    "\n",
    "# Table of removed users\n",
    "removed_users_table = outliers.reset_index()\n",
    "removed_users_table.columns = ['userId', 'num_ratings']\n",
    "\n",
    "print(removed_users_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3353a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a sparse matrix because the user-item matrix is very large and mostly empty\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Map user and movie IDs to indices\n",
    "user_ids = filtered_data['userId'].unique()\n",
    "movie_ids = filtered_data['movieId'].unique()\n",
    "user_to_idx = {uid: i for i, uid in enumerate(user_ids)}\n",
    "movie_to_idx = {mid: i for i, mid in enumerate(movie_ids)}\n",
    "\n",
    "# Create sparse matrix\n",
    "rows = filtered_data['userId'].map(user_to_idx)\n",
    "cols = filtered_data['movieId'].map(movie_to_idx)\n",
    "ratings = filtered_data['rating'].values\n",
    "user_item_matrix = csr_matrix((ratings, (rows, cols)), shape=(len(user_ids), len(movie_ids)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50169485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching movies found:\n",
      " - Whiplash (2014)\n",
      " - Whiplash (1948)\n",
      " - Whiplash (2013)\n"
     ]
    }
   ],
   "source": [
    "# This block can be used to look for movies in the dataset\n",
    "# Example search string\n",
    "search_string = \"whiplash\"\n",
    "\n",
    "# Convert both to lowercase for case-insensitive match\n",
    "matches = movies[movies['title'].str.lower().str.contains(search_string.lower())]['title'].tolist()\n",
    "\n",
    "if matches:\n",
    "    print(\"Matching movies found:\")\n",
    "    for m in matches:\n",
    "        print(\" -\", m)\n",
    "else:\n",
    "    print(\"No matches found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6abd915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Favorite movies with ratings\n",
    "my_favorites = {\n",
    "    \"Fight Club (1999)\": 5,\n",
    "    \"Interstellar (2014)\": 5,\n",
    "    \"Spirited Away (Sen to Chihiro no kamikakushi) (2001)\": 5,\n",
    "    \"Whiplash (2014)\": 5,\n",
    "}\n",
    "\n",
    "# Map movie titles to movieId\n",
    "movie_title_to_id = dict(zip(movies['title'], movies['movieId']))\n",
    "\n",
    "# Map movieId to column index in user-item matrix\n",
    "movie_to_idx = {mid: i for i, mid in enumerate(movie_ids)}\n",
    "\n",
    "# Create vector for favorites\n",
    "my_vector = np.zeros(len(movie_ids))\n",
    "\n",
    "for title, rating in my_favorites.items():\n",
    "    if title in movie_title_to_id:\n",
    "        mid = movie_title_to_id[title]\n",
    "        if mid in movie_to_idx:\n",
    "            my_vector[movie_to_idx[mid]] = rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce57c1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected movies statistics:\n",
      "'Fight Club (1999)', Avg = 4.24, # Ratings = 82858\n",
      "'Interstellar (2014)', Avg = 4.16, # Ratings = 38565\n",
      "'Spirited Away (Sen to Chihiro no kamikakushi) (2001)', Avg = 4.24, # Ratings = 33151\n",
      "'Whiplash (2014)', Avg = 4.17, # Ratings = 19446\n"
     ]
    }
   ],
   "source": [
    "# Create movie stats (mean rating and count per movie)\n",
    "movie_stats = filtered_data.groupby('movieId')['rating'].agg(['mean', 'count'])\n",
    "\n",
    "print(\"\\nSelected movies statistics:\")\n",
    "for title, rating in my_favorites.items():\n",
    "    if title in movie_title_to_id:\n",
    "        mid = movie_title_to_id[title]\n",
    "        if mid in movie_stats.index:\n",
    "            avg_rating = movie_stats.loc[mid, 'mean']\n",
    "            n_ratings = movie_stats.loc[mid, 'count']\n",
    "            print(f\"'{title}', \"\n",
    "                  f\"Avg = {avg_rating:.2f}, \"\n",
    "                  f\"# Ratings = {n_ratings}\")\n",
    "        else:\n",
    "            print(f\"'{title}' exists but has no ratings in the dataset.\")\n",
    "    else:\n",
    "        print(f\"'{title}' is NOT in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "192962e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most similar users:\n",
      "        userId  similarity\n",
      "91849   287289    0.707107\n",
      "95629   298958    0.707107\n",
      "7669     23827    0.706129\n",
      "37065   116239    0.706129\n",
      "15977    49700    0.702782\n",
      "65456   204175    0.670820\n",
      "35946   112579    0.670820\n",
      "100077  312811    0.670820\n",
      "25411    79619    0.636396\n",
      "103402  323307    0.615457\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between favorites vector and all users\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Find indices of favorite movies\n",
    "my_rated_movies = [movie_to_idx[movie_title_to_id[title]] \n",
    "                   for title in my_favorites if title in movie_title_to_id and movie_title_to_id[title] in movie_to_idx]\n",
    "\n",
    "# Select only users who rated at least one of these movies\n",
    "mask = np.any(user_item_matrix[:, my_rated_movies].toarray() > 0, axis=1)\n",
    "relevant_users_matrix = user_item_matrix[mask, :]\n",
    "\n",
    "similarities = cosine_similarity([my_vector], relevant_users_matrix)[0]\n",
    "\n",
    "# Map back to user IDs\n",
    "relevant_user_ids = user_ids[mask]\n",
    "similar_users_df = pd.DataFrame({'userId': relevant_user_ids, 'similarity': similarities})\n",
    "similar_users_df = similar_users_df.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "print(\"Top 10 most similar users:\")\n",
    "print(similar_users_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1440107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended movies for you:\n",
      "                                                title  score out of 5\n",
      "0   Howl's Moving Castle (Hauru no ugoku shiro) (2...            5.00\n",
      "1                                    Inception (2010)            5.00\n",
      "2                                     Parasite (2019)            5.00\n",
      "3                                      Shrek 2 (2004)            5.00\n",
      "4                            Good Will Hunting (1997)            4.76\n",
      "5                     The Shawshank Redemption (1994)            4.63\n",
      "6                             Schindler's List (1993)            4.52\n",
      "7                                 Forrest Gump (1994)            4.50\n",
      "8   Kiki's Delivery Service (Majo no takkyûbin) (1...            4.50\n",
      "9                                The Big Short (2015)            4.50\n",
      "10                                  The Batman (2022)            4.50\n",
      "11                                Pulp Fiction (1994)            4.48\n",
      "12                                  The Matrix (1999)            4.37\n",
      "13  The Lord of the Rings: The Return of the King ...            4.35\n",
      "14         Life Is Beautiful (La Vita è bella) (1997)            4.00\n",
      "15           Princess Mononoke (Mononoke-hime) (1997)            4.00\n",
      "16                                     Memento (2000)            4.00\n",
      "17                                        Dune (2021)            4.00\n",
      "18                                  Knives Out (2019)            3.95\n",
      "19                                  The Outfit (2022)            3.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vonks\\AppData\\Local\\Temp\\ipykernel_41016\\1245646477.py:18: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recommendation_scores = top_users_ratings.groupby('movieId').apply(\n"
     ]
    }
   ],
   "source": [
    "# Recommendation\n",
    "\n",
    "#Pick top-N similar users (top 25)\n",
    "top_users = similar_users_df.head(25)['userId'].values\n",
    "\n",
    "top_users_ratings = filtered_data[filtered_data['userId'].isin(top_users)]\n",
    "\n",
    "# Remove movies already rated\n",
    "my_rated_movie_ids = [movie_title_to_id[title] for title in my_favorites if title in movie_title_to_id]\n",
    "top_users_ratings = top_users_ratings[~top_users_ratings['movieId'].isin(my_rated_movie_ids)]\n",
    "\n",
    "top_users_ratings = top_users_ratings.merge(similar_users_df[['userId','similarity']], on='userId', how='left')\n",
    "\n",
    "# Compute weighted rating = rating * similarity\n",
    "top_users_ratings['weighted_rating'] = top_users_ratings['rating'] * top_users_ratings['similarity']\n",
    "\n",
    "# Aggregate by movieId: sum(weighted_rating) / sum(similarity)\n",
    "recommendation_scores = top_users_ratings.groupby('movieId').apply(\n",
    "    lambda x: x['weighted_rating'].sum() / x['similarity'].sum()\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# Map back to movie titles\n",
    "recommendations = recommendation_scores.reset_index().merge(movies, on='movieId')[['title', 0]]\n",
    "recommendations.columns = ['title', 'score out of 5']  # Renamed\n",
    "recommendations['score out of 5'] = recommendations['score out of 5'].round(2)\n",
    "\n",
    "# Fix titles (The, A, An)\n",
    "def fix_title(title):\n",
    "    if \", The\" in title:\n",
    "        return \"The \" + title.replace(\", The\", \"\")\n",
    "    elif \", A\" in title:\n",
    "        return \"A \" + title.replace(\", A\", \"\")\n",
    "    elif \", An\" in title:\n",
    "        return \"An \" + title.replace(\", An\", \"\")\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "recommendations['title'] = recommendations['title'].apply(fix_title)\n",
    "\n",
    "print(\"Top recommended movies for you:\")\n",
    "print(recommendations.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52712e64",
   "metadata": {},
   "source": [
    "This recommendation system works well if the selected movies are more similar and less niche, leading to high possible similarity with other users. Another requirement to get a good amount of recommendations is that similar users rated a decent amount of movies.\n",
    "\n",
    "In some cases where selected movies are more niche or very different, the system will not generate many recommendations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
